<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="default">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="deeplearning,机器学习,深度学习," />










<meta name="description" content="这篇博文主要讲的是关于deeplearning.ai的第四门课程的内容，《Convolutional Neural Networks》">
<meta property="og:type" content="article">
<meta property="og:title" content="Coursera-deeplearning-ai-（四）">
<meta property="og:url" content="http://drawwon.github.io/2018/05/10/Coursera-deeplearning-ai-%EF%BC%88%E5%9B%9B%EF%BC%89/index.html">
<meta property="og:site_name" content="WangZhao&#39;s Blog">
<meta property="og:description" content="这篇博文主要讲的是关于deeplearning.ai的第四门课程的内容，《Convolutional Neural Networks》">
<meta property="og:locale">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/21395179.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/16688061.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/23155888.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/45594204.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/36284135.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/56352677.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/88907670.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/92028937.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/69668519.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/57359168.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/24095269.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/97636140.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/9623750.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/11785024.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/71162365.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/43271742.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/32143114.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/27567213.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/91339029.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/35706558.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/26910954.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/23582594.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/99083203.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/3054087.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/88550955.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/37028773.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/68094398.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/23343715.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/34915820.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/4627273.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/36852562.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/27345434.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/90144873.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/89008645.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/73321754.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/87089704.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/5062663.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/92727700.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/71188004.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/27032753.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/76557389.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/36562583.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/76981350.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/70781915.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/4716774.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/65964893.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/31698060.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/39766648.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/21084208.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/12260966.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/7317445.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/15432401.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/38705005.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/49481234.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/10704951.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/66344361.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/35397965.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/58169041.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/56114233.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/52977504.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-16/99066781.jpg">
<meta property="og:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-16/8799779.jpg">
<meta property="article:published_time" content="2018-05-10T01:28:44.000Z">
<meta property="article:modified_time" content="2022-12-17T08:36:45.399Z">
<meta property="article:author" content="Jeffrey Pacino">
<meta property="article:tag" content="deeplearning">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/21395179.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://drawwon.github.io/2018/05/10/Coursera-deeplearning-ai-（四）/"/>





  <title>Coursera-deeplearning-ai-（四） | WangZhao's Blog</title>
  








<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WangZhao's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">It's not who you are underneath,it's what you do that defines you</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://drawwon.github.io/2018/05/10/Coursera-deeplearning-ai-%EF%BC%88%E5%9B%9B%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangZhao's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Coursera-deeplearning-ai-（四）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-10T09:28:44+08:00">
                2018-05-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这篇博文主要讲的是关于deeplearning.ai的第四门课程的内容，《Convolutional Neural Networks》</p>
<span id="more"></span>

<h2 id="Week-One"><a href="#Week-One" class="headerlink" title="Week One"></a>Week One</h2><h3 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h3><p>在处理计算机视觉问题的时候，我们可能处理的图片很大，之前我们用的都是64*64*3维度的图片，这样的图片不够清晰，如果我们用1000*1000*3大小的图片，每张图片的维度就是300w，这就需要很多的数据来调参，并且对系统的资源占用非常大，此时就要用到卷积的技巧，它是卷积神经网络的基础</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/21395179.jpg"></p>
<h3 id="利用卷积进行边缘检测的示例"><a href="#利用卷积进行边缘检测的示例" class="headerlink" title="利用卷积进行边缘检测的示例"></a>利用卷积进行边缘检测的示例</h3><p>比如我有如下左边这张图，我想检测这张图上面有些上面，我首先要用边缘检测，分别检测出他的横向边缘和纵向边缘</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/16688061.jpg"></p>
<p>边缘检测需要用到卷积，那么上面是卷积呢？</p>
<p>首先，假设我们现在有一张6*6的灰度图片（仅有一个rgb通道），我们定义一个3*3的filter，当然有些地方把这个filter称为kernel，我们这里就用filter来表示，那么现在用这个3*3的filter在6*6的图像上面移动，每移动一个位置进行元素乘积求和，最终得到一个4*4的结果矩阵，如下图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/23155888.jpg"></p>
<p>比如左上角的-5，是把3*3的矩阵放在6*6的矩阵的左上角得到的，也就是$-5&#x3D;3\times1+1\times1+2\times1+0\times0+5\times0+7\times0+1\times(-1)+8\times(-1)+2\times(-1)$</p>
<p>然后向右移动一个单位得到-4，一直移动下去得到右边的4*4矩阵</p>
<p>再举一个直观的例子，比如我们现在有个黑白分明的6*6灰度图片，我们要检测它的垂直边缘，用一个3*3的filter卷积，得到一个4*4的垂直边缘结果，如下</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/45594204.jpg"></p>
<p>4*4矩阵中间那块白色的就是边缘，此时看起来边缘很大，那是因为我们这里的原始图片太小了，如果原始图片的大小是1000*1000，那么这个边缘就非常合理了。这里这个边缘也显示了边缘的大体趋势，是正确的</p>
<p>卷积函数在几乎所有深度学习框架当中都有包含，比如TensorFlow当中的<code>tf.nn.conv2d</code></p>
<h3 id="更多的边缘检测"><a href="#更多的边缘检测" class="headerlink" title="更多的边缘检测"></a>更多的边缘检测</h3><p>边缘有着正边缘和负边缘的说法，从黑到白和从白到黑是不同的，如下图所示：</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/36284135.jpg"></p>
<p>当然，还有水平边缘和垂直边缘的区分，很容易想到水平边缘的filter就是大概将竖直边缘filter转动90度</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/56352677.jpg"></p>
<p>然后，根据filter使用的不同，也可以得到不同的边缘，比如常用的还有sobel filter，参数是1,2,1，还有scharr filter，参数是3,10,3，甚至你可以将这3*3的filter的9个值都设置为参数，通过反向传播来学习他们，由此你可以检测出任意角度的边缘，比如45度，70度，73度等等</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/88907670.jpg"></p>
<h3 id="padding-扩充"><a href="#padding-扩充" class="headerlink" title="padding 扩充"></a>padding 扩充</h3><p>上面讲到的直接卷积的方法有两个明显的缺点：</p>
<ol>
<li>图片会被缩小，你输入的是6*6的图片，最终得到的4*4的图片，比原始图片大小小了，如果经过若干层网络的卷积之后，得到的图片就相当小了</li>
<li>边缘信息利用得太少了，比如左上角那个像素，你在计算的过程中只会用到1次，但是中间的像素会用到很多次，那么左上角那个像素包含的信息的权重就被减小了</li>
</ol>
<p>假设我们输入一个n*n的图片，用一个f*f的filter进行卷积，那么最终得到的是一个n-f+1的图片</p>
<p>这时，我们可以使用padding的方法，一次解决上面提到的两个问题，所谓的padding就是将原来的图片向外扩充，扩充的值全部填成0，如下图所示</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/92028937.jpg"></p>
<p>假如我们扩充的大小是p，那么最终得到的图片大小就是n+2p-f+1，要使得最终的图片大小等于初始大小，那么p&#x3D;(f-1)&#x2F;2，f通常都是一个奇数，不是奇数的时候就要混合padding，就是左右padding的范围不一样</p>
<h3 id="带步长的卷积"><a href="#带步长的卷积" class="headerlink" title="带步长的卷积"></a>带步长的卷积</h3><p>通常的卷积是每次移动一格，但是如果你加上步长的话，每次就可以移动步长那么多格，比如你现在有一个7*7的图像，然后有个3*3的filter，如果你每次移动2步，那么最终得到的是一个3*3的图像</p>
<p>这个计算方法是加入你有一个n*n的图像，有一个f*f的filter，stride步长要s，padding的大小p，那么最终得到的图像大小为floor((n+2p-f)&#x2F;2 +1)，其中floor表示向下取整，以防这是一个非整数的情况</p>
<p>我们在神经网络中用的卷积准确来说应该叫做交叉相关，真正的卷积的filter应该先向右翻转90度，再上下翻转（翻转是为了满足矩阵卷积的结合律），但是因为约定，所以我们在神经网络中的交叉相关都被称为卷积</p>
<h3 id="卷积RGB图像"><a href="#卷积RGB图像" class="headerlink" title="卷积RGB图像"></a>卷积RGB图像</h3><p>我们之前卷积的都是黑白图像，如果我们需要卷积三通道的RGB图像，我们应该怎么做呢？</p>
<p>如下图，在卷积RGB图像的时候，我们可以用一个同样有三通道的filter进行卷积，filter的每个通道与RGB的红绿蓝三通道相乘并全部求和，最终得到的卷积结果是只有一个通道的而不是三个通道的</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/69668519.jpg"></p>
<p>当我们需要同时取得图像的垂直边缘，水平边缘或者更多的边缘的时候，我们应该怎么做呢？</p>
<p>如果你需要同时取得多个边缘，你只需要同时使用多个filter即可，得到的结果是很多张边缘图，你也可以把他们stack起来</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/57359168.jpg"></p>
<p>那么我们现在总结一下各个层的维度</p>
<p>输入的图片的维度是: $n\times n \times n_c$，其中$n_c$是指图片通道的数量</p>
<p>filter的维度是$f\times f \times n_c$，这里的filter的通道数和图片的通道数应该相同</p>
<p>得到的边缘结果的维度是$(n-f+1)\times (n-f+1) \times n_c^\prime$，其中$n_c^\prime$表示拥有的filter的数量</p>
<h3 id="单层卷积神经网络"><a href="#单层卷积神经网络" class="headerlink" title="单层卷积神经网络"></a>单层卷积神经网络</h3><p>首先你输入一个RGB三通道的图像，大小是6*6*3，然后通过两个filter，大小是3*3*3，得到两个4*4的Z，分别加上bias b1,b2，然后通过Relu函数进行非线性变换，得到4*4*2</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/24095269.jpg"></p>
<p>将这个单层的卷积神经网络与神经网络比较，这里的输入图像就是x,也就是$a^{[0]}$，通过的filter相当于w，之后的b相当于偏差，relu函数相当于激活函数g，得到的4*4*2的输出相当于$a^{[1]}$</p>
<p>让我们来看看这里面的参数及其维度</p>
<p>用L来表示一个卷积层，$f^{[l]}$表示filter的大小，$p^{[l]}$表示padding的大小，$s^{[l]}$表示stride的大小，$n_c^{[l]}$表示第l层filter的数量</p>
<p>那么输入的维度就是$n_H^{[l-1]}\times n_W^{[l-1]}\times n_c^{[l-1]}$</p>
<p>输出的维度是$n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$</p>
<p>其中的$n_H^{[l]}$和$n_W^{[l]}$可以用$n_H^{[l]}&#x3D;\lfloor \frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor$来计算</p>
<p>每一个filter的大小是：$f^{[l]} \times f^{[l]} \times n_c^{[l-1]}$，因为filter的通道要和输入相同</p>
<p>激活函数$a^{[l]}$的大小是$n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$，如果是批处理$A^{[l]}$的大小是$m \times n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$</p>
<p>权重w的大小是$f^{[l-1]}\times f^{[l-1]}\times n_c^{[l-1]} \times n_c^{[l]}$</p>
<p>偏差的大小是$n_c^{[l]}$</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-10/97636140.jpg"></p>
<h3 id="简单的卷积网络"><a href="#简单的卷积网络" class="headerlink" title="简单的卷积网络"></a>简单的卷积网络</h3><p>下图是一个简单的神经网络的例子，输入层的维度是39*39*3，第一层的$f^{[1]}&#x3D;3$，$s^{[1]}&#x3D;1$，$p^{[1]}&#x3D;0$，有10个filter，那么第一层的输出是37*37*10；第二层的$f^{[2]}&#x3D;5$，$s^{[1]}&#x3D;2$，$p^{[2]}&#x3D;0$，filter个数是20，第二层的输出是17*17*20；第三层的$f^{[3]}&#x3D;5$，$s^{[3]}&#x3D;2$，$p^{[3]}&#x3D;0$，filter个数是40，输出是7*7*40</p>
<p>然后，将得到的7*7*40的图像flatten成一个7*7*40&#x3D;1960*1的向量，然后把这个向量输入一个logistics或softmax函数，以此进行分类</p>
<p>通常来说，卷积网络的图像大小会越来越小，但通道数会越来越多</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/9623750.jpg"></p>
<p>卷及网络中的典型层有：</p>
<ol>
<li>Convolution (conv)</li>
<li>Pooling（pool）</li>
<li>Fully connected (FC)</li>
</ol>
<h3 id="Pooling-Layers"><a href="#Pooling-Layers" class="headerlink" title="Pooling Layers"></a>Pooling Layers</h3><p>利用pooling layer去减小表达的大小，加速计算，并使得某些特征更加稳定</p>
<p>pooling layer最常用的就是max pooling，就是用一个filter去移动，但是不是相乘求和，而是求出这个filter移动过程中的最大值，如下所示</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/11785024.jpg"></p>
<p>还有一种pooling叫做average pooling，不是求最大值而是平均值，这种pooling用的非常少</p>
<h3 id="一个完整的卷积神经网络示例"><a href="#一个完整的卷积神经网络示例" class="headerlink" title="一个完整的卷积神经网络示例"></a>一个完整的卷积神经网络示例</h3><p>如图，我们输入一个32*32*3的网络，经过一个conv1层，f&#x3D;5,s&#x3D;1，得到一个28*28*6的输出，然后经一个maxpoo层pool1，得到14*14*6，这个conv1和pool1被合称为layer1，因为layer只算那些有参数的层，pool层没有参数，所以conv1和pool1合称一层layer1</p>
<p>然后经过conv2,f&#x3D;5,s&#x3D;1，得到10*10*16，然后经过pool2，得到5*5*16</p>
<p>此时flatten成400*1的向量，然后用普通的神经网络继续传输，此时用普通神经网络的层被称之为fully connected层，W[3]的参数是(120,400)，所以a[3]&#x3D;(120,1)，然后w[4]&#x3D;(84,120)，得到a[4]&#x3D;(84,1)，然后经过一个softmax层，因为我们这里是分类数字0-9，所以最后的输出是(10,1)，然后选择概率最大那个</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/71162365.jpg"></p>
<h3 id="为什么要用卷积神经网络"><a href="#为什么要用卷积神经网络" class="headerlink" title="为什么要用卷积神经网络"></a>为什么要用卷积神经网络</h3><p>卷积神经网络可以显著地减少参数，我们来看个例子</p>
<p>如下图你有一个卷积层，本来大小是32*32*3，经过一个卷积层之后大小成了28*28*6，那么你用到的参数个数应该是5*5*6+6&#x3D;156个，如果你直接用全联通层，那么你需要的参数个数是32*32*3*28*28*6&#x3D;14M个，明显这里的参数就非常多了</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/43271742.jpg"></p>
<p>还有种解释是卷及网络有参数共享和稀疏连接的好处</p>
<p>如图，你通过卷积层得到的每一个值，都只与自己的那9个卷积的值相关，与别的值不相关，这就是稀疏连接的意思，各个值之间不干扰</p>
<p>参数共享的意思是，比如你有一个3*3的filter，可以进行垂直边缘检测，那么这个filter无论是在<strong>同一张图</strong>的哪个地方，都可以进行边缘检测，而不是说只能在某个地方进行</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-11/32143114.jpg"></p>
<h3 id="利用TensorFlow搭建卷积神经网络"><a href="#利用TensorFlow搭建卷积神经网络" class="headerlink" title="利用TensorFlow搭建卷积神经网络"></a>利用TensorFlow搭建卷积神经网络</h3><p>这周的编程作业就是利用TensorFlow搭建卷积神经网络，那么我们对程序回顾一下</p>
<h4 id="read-data"><a href="#read-data" class="headerlink" title="read data"></a>read data</h4><p>先看看数据读入的程序</p>
<p>数据是存在f5文件中的，用h5py进行读取，然后通过key访问，查看key的方法是list(data.keys())，然后访问某个key下的所有数据的方法是<code>data[&#39;key&#39;][:]</code>，如果不加最后的<code>[:]</code>，那么你取到的是一个h5对象，然后将y reshape成一个行向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_dataset</span>():</span><br><span class="line">    train_dataset = h5py.File(<span class="string">&#x27;datasets/train_signs.h5&#x27;</span>, <span class="string">&quot;r&quot;</span>)</span><br><span class="line">    train_set_x_orig = np.array(train_dataset[<span class="string">&quot;train_set_x&quot;</span>][:]) <span class="comment"># your train set features</span></span><br><span class="line">    train_set_y_orig = np.array(train_dataset[<span class="string">&quot;train_set_y&quot;</span>][:]) <span class="comment"># your train set labels</span></span><br><span class="line"></span><br><span class="line">    test_dataset = h5py.File(<span class="string">&#x27;datasets/test_signs.h5&#x27;</span>, <span class="string">&quot;r&quot;</span>)</span><br><span class="line">    test_set_x_orig = np.array(test_dataset[<span class="string">&quot;test_set_x&quot;</span>][:]) <span class="comment"># your test set features</span></span><br><span class="line">    test_set_y_orig = np.array(test_dataset[<span class="string">&quot;test_set_y&quot;</span>][:]) <span class="comment"># your test set labels</span></span><br><span class="line"></span><br><span class="line">    classes = np.array(test_dataset[<span class="string">&quot;list_classes&quot;</span>][:]) <span class="comment"># the list of classes</span></span><br><span class="line">    </span><br><span class="line">    train_set_y_orig = train_set_y_orig.reshape((<span class="number">1</span>, train_set_y_orig.shape[<span class="number">0</span>]))</span><br><span class="line">    test_set_y_orig = test_set_y_orig.reshape((<span class="number">1</span>, test_set_y_orig.shape[<span class="number">0</span>]))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes</span><br></pre></td></tr></table></figure>

<h4 id="one-hot-transfer"><a href="#one-hot-transfer" class="headerlink" title="one_hot transfer"></a>one_hot transfer</h4><p>接下来是一个one_hot y label 的转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">convert_to_one_hot</span>(<span class="params">Y, C</span>):</span><br><span class="line">    Y = np.eye(C)[Y.reshape(-<span class="number">1</span>)].T</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>

<p>np.eye后面跟一个array，就可以制造一个多行的one_hot值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">np.eye(<span class="number">6</span>)[np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])]</span><br><span class="line"><span class="comment">#array([[0., 1., 0., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#       [0., 0., 1., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#       [0., 1., 0., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#       [0., 1., 0., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#       [0., 1., 0., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#       [0., 1., 0., 0., 0., 0.]])</span></span><br></pre></td></tr></table></figure>

<p>当然你也可以用tf.one_hot函数来实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">indices = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">depth = <span class="number">3</span></span><br><span class="line">one = tf.one_hot(indices, depth)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(sess.run(one))</span><br><span class="line"><span class="comment">#[[1. 0. 0.]</span></span><br><span class="line"> <span class="comment">#[0. 1. 0.]</span></span><br><span class="line"> <span class="comment">#[0. 0. 1.]]</span></span><br></pre></td></tr></table></figure>

<h4 id="Create-Placeholder"><a href="#Create-Placeholder" class="headerlink" title="Create Placeholder"></a>Create Placeholder</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: create_placeholders</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_placeholders</span>(<span class="params">n_H0, n_W0, n_C0, n_y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Creates the placeholders for the tensorflow session.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    n_H0 -- scalar, height of an input image</span></span><br><span class="line"><span class="string">    n_W0 -- scalar, width of an input image</span></span><br><span class="line"><span class="string">    n_C0 -- scalar, number of channels of the input</span></span><br><span class="line"><span class="string">    n_y -- scalar, number of classes</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype &quot;float&quot;</span></span><br><span class="line"><span class="string">    Y -- placeholder for the input labels, of shape [None, n_y] and dtype &quot;float&quot;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈2 lines)</span></span><br><span class="line">    X = tf.placeholder(dtype=tf.float32,shape=(<span class="literal">None</span>, n_H0, n_W0, n_C0))</span><br><span class="line">    Y = tf.placeholder(dtype=tf.float32,shape=(<span class="literal">None</span>,n_y))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure>

<p>tf.placeholder是建立占位符</p>
<p>None是因为不确定每次输入多少张图片，然后X的维度是height，width，n_c0，y的维度是n_y</p>
<h4 id="initialize-parameters"><a href="#initialize-parameters" class="headerlink" title="initialize_parameters"></a>initialize_parameters</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_parameters</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Initializes weight parameters to build a neural network with tensorflow. The shapes are:</span></span><br><span class="line"><span class="string">                        W1 : [4, 4, 3, 8]</span></span><br><span class="line"><span class="string">                        W2 : [2, 2, 8, 16]</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- a dictionary of tensors containing W1, W2</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                              <span class="comment"># so that your &quot;random&quot; numbers match ours</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 2 lines of code)</span></span><br><span class="line">    W1 = tf.get_variable(<span class="string">&#x27;W1&#x27;</span>,shape=[<span class="number">4</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">8</span>],initializer=tf.contrib.layers.xavier_initializer(seed = <span class="number">0</span>))</span><br><span class="line">    W2 = tf.get_variable(<span class="string">&#x27;W2&#x27;</span>,shape=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">8</span>,<span class="number">16</span>],initializer=tf.contrib.layers.xavier_initializer(seed = <span class="number">0</span>))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    parameters = &#123;<span class="string">&quot;W1&quot;</span>: W1,</span><br><span class="line">                  <span class="string">&quot;W2&quot;</span>: W2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<p>tf.get_variable 用于建立变量，第一维的参数是f&#x3D;4,个数是8个；第二维的参数是f&#x3D;2，个数是16个</p>
<h4 id="Forward-propagation"><a href="#Forward-propagation" class="headerlink" title="Forward propagation"></a>Forward propagation</h4><p>我们这里输入parameter和X，网络的结构如下</p>
<p><code>CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</code> </p>
<p>用<code>tf.nn.conv2d(X,W1,strides=[1, 1, 1, 1],padding=&#39;SAME&#39;)</code>进行卷积，输入A和W，步长的输入方式是[batch,s,s,depth]，batch表示每次跳过多少张图片，depth表示跳过多少通道；padding的方法是’SAME’</p>
<p>每个conv2d的输出是Z，relu之后是A，maxpool之后是P</p>
<p>把图片flatten到一维， <code>P2 = tf.contrib.layers.flatten(P2)</code></p>
<p><code>tf.contrib.layers.fully_connected(P2, num_outputs=6, activation_fn=None)</code>表示全连接层，不用activation_fn是因为最终计算cost的时候会自动用到softmax函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: forward_propagation</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_propagation</span>(<span class="params">X, parameters</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implements the forward propagation for the model:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset placeholder, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;W2&quot;</span></span><br><span class="line"><span class="string">                  the shapes are given in initialize_parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    Z3 -- the output of the last LINEAR unit</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve the parameters from the dictionary &quot;parameters&quot; </span></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># CONV2D: stride of 1, padding &#x27;SAME&#x27;</span></span><br><span class="line">    Z1 = tf.nn.conv2d(X,W1,strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A1 = tf.nn.relu(Z1)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 8x8, sride 8, padding &#x27;SAME&#x27;</span></span><br><span class="line">    P1 = tf.nn.max_pool(A1,ksize=[<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>],strides=[<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    <span class="comment"># CONV2D: filters W2, stride 1, padding &#x27;SAME&#x27;</span></span><br><span class="line">    Z2 = tf.nn.conv2d(P1,W2,strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A2 = tf.nn.relu(Z2)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 4x4, stride 4, padding &#x27;SAME&#x27;</span></span><br><span class="line">    P2 = tf.nn.max_pool(A2,ksize=[<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>],strides=[<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    <span class="comment"># FLATTEN</span></span><br><span class="line">    P2 = tf.contrib.layers.flatten(P2)</span><br><span class="line">    <span class="comment"># FULLY-CONNECTED without non-linear activation function (not not call softmax).</span></span><br><span class="line">    <span class="comment"># 6 neurons in output layer. Hint: one of the arguments should be &quot;activation_fn=None&quot; </span></span><br><span class="line">    Z3 = tf.contrib.layers.fully_connected(P2, num_outputs=<span class="number">6</span>, activation_fn=<span class="literal">None</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z3</span><br></pre></td></tr></table></figure>

<h4 id="计算代价"><a href="#计算代价" class="headerlink" title="计算代价"></a>计算代价</h4><p><code>tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y)</code>，logists表示输出，label表示真正的标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: compute_cost </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_cost</span>(<span class="params">Z3, Y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes the cost</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)</span></span><br><span class="line"><span class="string">    Y -- &quot;true&quot; labels vector placeholder, same shape as Z3</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost - Tensor of the cost function</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line of code)</span></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>

<h4 id="建立model"><a href="#建立model" class="headerlink" title="建立model"></a>建立model</h4><p>先获取shape，然后定义placeholder</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(m, n_H0, n_W0, n_C0) = X_train.shape             </span><br><span class="line">n_y = Y_train.shape[<span class="number">1</span>]</span><br><span class="line">costs = []                                        <span class="comment"># To keep track of the cost</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Placeholders of the correct shape</span></span><br><span class="line">X, Y = create_placeholders(n_H0,n_W0,n_C0,n_y)</span><br></pre></td></tr></table></figure>

<p>然后定义参数w1，w2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_parameters()</span><br></pre></td></tr></table></figure>

<p>然后进行前向传播</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z3 = forward_propagation(X,parameters)</span><br></pre></td></tr></table></figure>

<p>然后计算cost</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z3 = forward_propagation(X,parameters)</span><br></pre></td></tr></table></figure>

<p>设置optimizer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.AdamOptimizer().minimize(cost)</span><br></pre></td></tr></table></figure>

<p>进行参数初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure>

<p>然后开始循环epochs，其中的minibatch的取法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_mini_batches</span>(<span class="params">X, Y, mini_batch_size = <span class="number">64</span>, seed = <span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Creates a list of random minibatches from (X, Y)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)</span></span><br><span class="line"><span class="string">    Y -- true &quot;label&quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)</span></span><br><span class="line"><span class="string">    mini_batch_size - size of the mini-batches, integer</span></span><br><span class="line"><span class="string">    seed -- this is only for the purpose of grading, so that you&#x27;re &quot;random minibatches are the same as ours.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    m = X.shape[<span class="number">0</span>]                  <span class="comment"># number of training examples</span></span><br><span class="line">    mini_batches = []</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Shuffle (X, Y)</span></span><br><span class="line">    permutation = <span class="built_in">list</span>(np.random.permutation(m))</span><br><span class="line">    shuffled_X = X[permutation,:,:,:]</span><br><span class="line">    shuffled_Y = Y[permutation,:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.</span></span><br><span class="line">    num_complete_minibatches = math.floor(m/mini_batch_size) <span class="comment"># number of mini batches of size mini_batch_size in your partitionning</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_complete_minibatches):</span><br><span class="line">        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]</span><br><span class="line">        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]</span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Handling the end case (last mini-batch &lt; mini_batch_size)</span></span><br><span class="line">    <span class="keyword">if</span> m % mini_batch_size != <span class="number">0</span>:</span><br><span class="line">        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]</span><br><span class="line">        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]</span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> mini_batches</span><br></pre></td></tr></table></figure>







<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: model</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">X_train, Y_train, X_test, Y_test, learning_rate = <span class="number">0.009</span>,</span></span><br><span class="line"><span class="params">          num_epochs = <span class="number">100</span>, minibatch_size = <span class="number">64</span>, print_cost = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implements a three-layer ConvNet in Tensorflow:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X_train -- training set, of shape (None, 64, 64, 3)</span></span><br><span class="line"><span class="string">    Y_train -- test set, of shape (None, n_y = 6)</span></span><br><span class="line"><span class="string">    X_test -- training set, of shape (None, 64, 64, 3)</span></span><br><span class="line"><span class="string">    Y_test -- test set, of shape (None, n_y = 6)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the optimization</span></span><br><span class="line"><span class="string">    num_epochs -- number of epochs of the optimization loop</span></span><br><span class="line"><span class="string">    minibatch_size -- size of a minibatch</span></span><br><span class="line"><span class="string">    print_cost -- True to print the cost every 100 epochs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    train_accuracy -- real number, accuracy on the train set (X_train)</span></span><br><span class="line"><span class="string">    test_accuracy -- real number, testing accuracy on the test set (X_test)</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    ops.reset_default_graph()                         <span class="comment"># to be able to rerun the model without overwriting tf variables</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                             <span class="comment"># to keep results consistent (tensorflow seed)</span></span><br><span class="line">    seed = <span class="number">3</span>                                          <span class="comment"># to keep results consistent (numpy seed)</span></span><br><span class="line">    (m, n_H0, n_W0, n_C0) = X_train.shape             </span><br><span class="line">    n_y = Y_train.shape[<span class="number">1</span>]                            </span><br><span class="line">    costs = []                                        <span class="comment"># To keep track of the cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Placeholders of the correct shape</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    X, Y = create_placeholders(n_H0,n_W0,n_C0,n_y)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Forward propagation: Build the forward propagation in the tensorflow graph</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    Z3 = forward_propagation(X,parameters)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Cost function: Add cost function to tensorflow graph</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    cost = compute_cost(Z3,Y)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    optimizer = tf.train.AdamOptimizer().minimize(cost)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize all the variables globally</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># Start the session to compute the tensorflow graph</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run the initialization</span></span><br><span class="line">        sess.run(init)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Do the training loop</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line"></span><br><span class="line">            minibatch_cost = <span class="number">0.</span></span><br><span class="line">            num_minibatches = <span class="built_in">int</span>(m / minibatch_size) <span class="comment"># number of minibatches of size minibatch_size in the train set</span></span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Select a minibatch</span></span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                <span class="comment"># IMPORTANT: The line that runs the graph on a minibatch.</span></span><br><span class="line">                <span class="comment"># Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).</span></span><br><span class="line">                <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">                _ , temp_cost = sess.run([optimizer,cost], feed_dict=&#123;X:minibatch_X, Y: minibatch_Y&#125;)</span><br><span class="line">                <span class="comment">### END CODE HERE ###</span></span><br><span class="line">                </span><br><span class="line">                minibatch_cost += temp_cost / num_minibatches</span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">            <span class="comment"># Print the cost every epoch</span></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span> (<span class="string">&quot;Cost after epoch %i: %f&quot;</span> % (epoch, minibatch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(minibatch_cost)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># plot the cost</span></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;cost&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;iterations (per tens)&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;Learning rate =&quot;</span> + <span class="built_in">str</span>(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the correct predictions</span></span><br><span class="line">        predict_op = tf.argmax(Z3, <span class="number">1</span>)</span><br><span class="line">        correct_prediction = tf.equal(predict_op, tf.argmax(Y, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculate accuracy on the test set</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">&quot;float&quot;</span>))</span><br><span class="line">        <span class="built_in">print</span>(accuracy)</span><br><span class="line">        train_accuracy = accuracy.<span class="built_in">eval</span>(&#123;X: X_train, Y: Y_train&#125;)</span><br><span class="line">        test_accuracy = accuracy.<span class="built_in">eval</span>(&#123;X: X_test, Y: Y_test&#125;)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Train Accuracy:&quot;</span>, train_accuracy)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Test Accuracy:&quot;</span>, test_accuracy)</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> train_accuracy, test_accuracy, parameters</span><br></pre></td></tr></table></figure>

<p>然后run这个optimizer和cost</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_ , temp_cost = sess.run([optimizer,cost], feed_dict=&#123;X:minibatch_X, Y: minibatch_Y&#125;)</span><br></pre></td></tr></table></figure>



<h2 id="Week-Two"><a href="#Week-Two" class="headerlink" title="Week Two"></a>Week Two</h2><h3 id="经典网络"><a href="#经典网络" class="headerlink" title="经典网络"></a>经典网络</h3><h4 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h4><p>这个网络是在1998年提出的，结果如下图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/27567213.jpg"></p>
<p>一共有大概60K个参数，第一层是6个5*5的conv layer，然后是一个f&#x3D;2,s&#x3D;2的pool layer（当时用的的average pool，不过后来证明max pool更有效），然后再来16个5*5的conv layer，然后是一个f&#x3D;2,s&#x3D;2的pool layer，然后将这个5*5*16的volume flatten为一个(400,1)的向量，经过一个fc（fully connected) layer，变成120*1,在经过一个fc layer，变成84*1的，再经过一个softmax得到一个10*1的$\hat{y}$，用于判别手写数字0-9</p>
<h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><p>AlexNet是在2012年提出的，这个网络让人们开始觉得深度学习的确可以在图像和自然语言处理等方面表现的很好</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/91339029.jpg"></p>
<p>这个网络的结构是一个conv layer，跟一个max pool layer，再来一个conv layer，跟一个max-pool layer，接下来3个conv layer，跟一个max-pool layer，这时flatten为一个9216*1的向量，然后接一个FC layer，再接一个FC layer，再接一个softmax，得到输出</p>
<p>参数的个数为$(11<em>11</em>3+1)<em>96+(5</em>5<em>96+1)<em>256+(3</em>3</em>256+1)<em>384+(3</em>3<em>384+1)<em>384</em>2 + 9216</em>4096 + 4096<em>4096+1000</em>4096&#x3D;62811648$，约为60million个</p>
<h4 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG-16"></a>VGG-16</h4><p>这个网络在2015年提出，整个网络中用到的filter都是3*3的,padding都是same，用到的max-pool layer 都是f&#x3D;2,s&#x3D;2,</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/35706558.jpg"></p>
<p>先是2层conv 64的 conv layer，然后经过一个pool layer，接下来2层128个的conv layer，接下来一个pool layer，再接下来3层256个的conv layer，接一个pool layer，再接一个3层512个的conv layer，接一个pool layer，接一层512个的conv layer，接一个pool layer，接2层FC layer，接一层softmax</p>
<p>为什么叫VGG-16呢，因为这个网络里有参数的层一个是16个</p>
<p>同时提出的还有VGG-19，但是VGG-16的效果一般来说跟VGG-19差不多，并且参数要相对少一些，所以一般都用VGG-16</p>
<p>VGG-16参数非常多，大概有138million个，即使对于现代计算机，计算起来也是比较吃力的</p>
<h3 id="残差网络-ResNet"><a href="#残差网络-ResNet" class="headerlink" title="残差网络(ResNet)"></a>残差网络(ResNet)</h3><p>残差网络首先要理解什么是残差块(Residual block)</p>
<p>假如你现在有一个如下的2层的神经网络，每次经过一个线性层，然后一个ReLU非线性层，到达下一层，如图所示</p>
<p>从左到右依次进行的被称为full path，然而如果你直接将$a^{[l]}$加到最后一个ReLU之前，这样的方法叫做short cut 或者是 skip connection，此时我们称这样一个有跳跃连接的整体为一个Residual block</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/26910954.jpg"></p>
<p>如果我们有一个10层的神经网络，每2层形成一个残差块，那么这个网络就被称为残差网络，如下图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/23582594.jpg"></p>
<p>残差网络在实际中表现比普通网络更好，具体表现在：随着网络层数的增加，普通网络的训练错误会先降低后增加（因为层数增多，普通网络的训练越来越难，到后面规定的iteration还没有收敛，所以training error又增加了）；但是残差网络会一直下降，直到基本不下降的状态，不会出现training error上升的情况</p>
<p>我们用plain表示普通网络，ResNet表示残差网络，得到如下的training error和layers的示意图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/99083203.jpg"></p>
<h3 id="为什么残差网络可以表现得更好"><a href="#为什么残差网络可以表现得更好" class="headerlink" title="为什么残差网络可以表现得更好"></a>为什么残差网络可以表现得更好</h3><ul>
<li><p>Lets see some example that illustrates why resNet work.</p>
<ul>
<li><p>We have a big NN as the following:</p>
<ul>
<li><code>X --&gt; Big NN --&gt; a[l]</code></li>
</ul>
</li>
<li><p>Lets add two layers to this network as a residual block:</p>
<ul>
<li><code>X --&gt; Big NN --&gt; a[l] --&gt; Layer1 --&gt; Layer2 --&gt; a[l+2]</code></li>
<li>And a<code>[l]</code> has a direct connection to <code>a[l+2]</code></li>
</ul>
</li>
<li><p>Suppose we are using RELU activations.</p>
</li>
<li><p>Then:</p>
<p><code>a[l+2] = g( z[l+2] + a[l] ) = g( W[l+2] a[l+1] + b[l+2] + a[l] )</code> </p>
</li>
<li><p>Then if we are using L2 regularization for example, <code>W[l+2]</code> will be zero. Lets say that <code>b[l+2]</code> will be zero too.</p>
</li>
<li><p>Then <code>a[l+2] = g( a[l] ) = a[l]</code> with no negative values.</p>
</li>
<li><p>This show that identity function is easy for a residual block to learn. And that why it can train deeper NNs.</p>
</li>
<li><p>Also that the two layers we added doesn’t hurt the performance of big NN we made.</p>
</li>
<li><p>Hint: dimensions of z[l+2] and a[l] have to be the same in resNets. In case they have different dimensions what we put a matrix parameters (Which can be learned or fixed)</p>
<ul>
<li><code>a[l+2] = g( z[l+2] + ws * a[l] ) # The added Ws should make the dimentions equal</code></li>
<li>ws also can be a zero padding.</li>
</ul>
</li>
</ul>
</li>
<li><p>Using a skip-connection helps the gradient to backpropagate and thus helps you to train deeper networks</p>
</li>
</ul>
<p>主要起作用的原因是redidual network 阻止了梯度消失和梯度爆炸之类的问题</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-12/3054087.jpg"></p>
<h3 id="1-times-1-的卷积（network-in-network）"><a href="#1-times-1-的卷积（network-in-network）" class="headerlink" title="$1\times 1$的卷积（network in network）"></a>$1\times 1$的卷积（network in network）</h3><p>1*1的卷积主要是为了改变图片的通道数目，比如你现在有一个28*28*192的图片，你可以将它变成32通道的，以此来减少计算量，也可以把它变成192通道的，这相当于在原来的图片上加了一个192通道的图片，这将使得模型更复杂，以此来表征更加复杂的模型</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/88550955.jpg"></p>
<h3 id="Inception-Network"><a href="#Inception-Network" class="headerlink" title="Inception Network"></a>Inception Network</h3><p>在设计神经网络的时候，你可能会想如何去选择conv layer 所用的filter的大小，以及max-pool的大小，这个时候其实你可以把所有你可能会想要用到的conv layer和max-pool layer联结起来，形成一个复杂的网络，具体如下：</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/37028773.jpg"></p>
<p>所有的conv layer和max-pool layer都用到了same padding，这样保证经过一个layer之后的维度不变，以便大家能够联结起来</p>
<p>但是inception network造成的问题就是计算量太大，比如我们现在来看看5*5这组filter的乘法的数目，一共输出是28*28*32个，每个输出所要求的乘法数目是5*5*192，所以全部乘起来之后是28*28*32*5*5*192&#x3D;120M次</p>
<p>我们可以用上一节提到的1*1的conv 层进行计算次数的优化，用1*1的conv 层计算出一个 bottleneck layer（瓶颈层:和瓶颈一样，先变小，再变大），然后再计算乘法。具体来说是将28*28*192的图片先经过一个1*1的个数为16的层，变成28*28*16的层，然后再经过5*5的层，计算数量缩减为12.4M，如下图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/68094398.jpg"></p>
<p>一个Inception module如下图所示，包含1*1的conv layer 和 3*3的conv layer(前面有一个1*1的bottleneck layer)和5*5的conv layer(前面有一个1*1的bottleneck layer)，以及一个3*3的max-pool layer（后面有一个1*1的layer用于减小通道数）</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/23343715.jpg"></p>
<p>一个完整的inception network如下图所示，由多个inception module组成，中间还有一个side branch，用中间某一层的输出进行预测</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/34915820.jpg"></p>
<h3 id="使用开源的深度学习实现"><a href="#使用开源的深度学习实现" class="headerlink" title="使用开源的深度学习实现"></a>使用开源的深度学习实现</h3><p>当你遇到一个想要去实现的网络的时候，从头开始动手实现是非常困难的，因为有很多调参之类的问题需要你去解决，那么你完全可以使用google 去搜索github上面的结果，比如你先想要实现ResNet， 你只需要在google上面搜索ResNet github，很容易就能找到一个结果，并且这些开源代码往往用了大量的原始数据进行训练，你只需要下下来进行迁移学习就行了</p>
<h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p>比如你现在想要是别的两只猫，分别叫做tigger和misty，但是你拥有的这两只猫的图片很少，所以你从网上下了一个在非常大数据集上面训练的模型(比如image net上训练过的模型)，然后你直接去掉输出层，把前面的所有层的参数都freeze住，对最后一层进行训练，就得到了你的猫分类器</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/4627273.jpg"></p>
<p>当然，如果你数据量大一些，你可以少冻住几层，多训练几层，这个freeze的方法，通常是将输入输进去，用原来的网络参数计算直到你要自己训练的那层，把这些数据存下来作为新网络的输入。后面网络参数的初始化可以直接用别人训练好的参数作为反向传播</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/36852562.jpg"></p>
<p>除非你数据量非常大，不然你都不要完全重新训练网络</p>
<h3 id="数据提升"><a href="#数据提升" class="headerlink" title="数据提升"></a>数据提升</h3><p>数据提升主要有两种方法，一种是在图片内容上的变换，一种是色彩上的变换</p>
<p>内容上的变换主要有：镜像变换，随机裁剪，旋转，扭曲等等，如下图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/27345434.jpg"></p>
<p>色彩上的变换主要是：增加或减少RGB色彩，比较高级的方法叫做PCA color augmentation，效果如图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/90144873.jpg"></p>
<h3 id="计算机视觉任务的经验"><a href="#计算机视觉任务的经验" class="headerlink" title="计算机视觉任务的经验"></a>计算机视觉任务的经验</h3><p>一般来说，数据越多，你所需要进行的手动修改的部分就越少，如图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/89008645.jpg"></p>
<p>在标准数据集或者是竞赛当中有一些比较常用的方法：</p>
<ol>
<li>Ensembling：训练多个神经网络并平均输出</li>
<li>多种图片裁剪的数据提升方法：原图以及镜像图片的正中心，左上角，右上角，左下角，右下角图片，这个方法被称为crop-10，因为一共裁剪出10张</li>
</ol>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/73321754.jpg"></p>
<p>在使用开源框架的时候，通常可以：</p>
<ol>
<li>用论文中提出的框架，因为一般计算机视觉任务有通用性</li>
<li>使用开源框架</li>
<li>使用pre-trained model并调整你模型中的参数</li>
</ol>
<h3 id="Keras-tutorial"><a href="#Keras-tutorial" class="headerlink" title="Keras tutorial"></a>Keras tutorial</h3><p>Keras更像是sklearn的过程，每一层的叠加都是可见的，然后最后compile一下model，fit model，然后evaluate model</p>
<p>具体来说，我们看看一个1层的卷积神经网络怎么实现的</p>
<p>先用Input函数得到输入，用ZeroPadding2d函数进行zero padding，用Conv2D进行卷积，用BatchNormalization进行批量正则化（每一层都进行正则化而不只是输入正则化），经过一个激活函数Activation(‘relu’)，用MaxPooling2D经过一个max pool，然后Flatten，然后用一个sigmoid函数得到输出，最后用<code>model=Model(inputs=..., outputs=... ,name=&#39;...&#39;)</code>建立模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">input_shape</span>):</span><br><span class="line">    <span class="comment"># Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!</span></span><br><span class="line">    X_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero-Padding: pads the border of X_input with zeroes</span></span><br><span class="line">    X = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(X_input)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># CONV -&gt; BN -&gt; RELU Block applied to X</span></span><br><span class="line">    X = Conv2D(<span class="number">32</span>, (<span class="number">7</span>, <span class="number">7</span>), strides = (<span class="number">1</span>, <span class="number">1</span>), name = <span class="string">&#x27;conv0&#x27;</span>)(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = <span class="string">&#x27;bn0&#x27;</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># MAXPOOL</span></span><br><span class="line">    X = MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">&#x27;max_pool&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># FLATTEN X (means convert it to a vector) + FULLYCONNECTED</span></span><br><span class="line">    X = Flatten()(X)</span><br><span class="line">    X = Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, name=<span class="string">&#x27;fc&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create model. This creates your Keras model instance, you&#x27;ll use this instance to train/test the model.</span></span><br><span class="line">    model = Model(inputs = X_input, outputs = X, name=<span class="string">&#x27;HappyModel&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>You have now built a function to describe your model. To train and test this model, there are four steps in Keras:</p>
<ol>
<li>Create the model by calling the function above</li>
<li>Compile the model by calling <code>model.compile(optimizer = &quot;...&quot;, loss = &quot;...&quot;, metrics = [&quot;accuracy&quot;])</code></li>
<li>Train the model on train data by calling <code>model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)</code></li>
<li>Test the model on test data by calling <code>model.evaluate(x = ..., y = ...)</code></li>
</ol>
<p>If you want to know more about <code>model.compile()</code>, <code>model.fit()</code>, <code>model.evaluate()</code> and their arguments, refer to the official <a href="https://keras.io/models/model/">Keras documentation</a>.</p>
<p>现在建立模型的方法就是四步：</p>
<ol>
<li>定义模型：<code>happyModel = HappyModel(X_train.shape[1:])</code></li>
<li>compile模型，定义其中的optimizer和loss以及metrics，<code>happyModel.compile(optimizer = &quot;Adam&quot;, loss = &quot;binary_crossentropy&quot;, metrics = [&quot;accuracy&quot;])</code></li>
<li>fit模型：<code>happyModel.fit(x = X_train, y = Y_train, epochs = 5, batch_size = 16)</code>，这里的batch-size选为16，一开始用了64，效果非常不好</li>
<li>evaluate模型：<code>preds = happyModel.evaluate(x = X_, y = ...)</code></li>
</ol>
<p>keras当中比较有用的两个函数：</p>
<ol>
<li>模型的每一层的参数个数：<code>happyModel.summary()</code></li>
<li><code>plot_model(happyModel, to_file=&#39;HappyModel.png&#39;)</code><br><code>SVG(model_to_dot(happyModel).create(prog=&#39;dot&#39;, format=&#39;svg&#39;))</code><br>上面两行用于打印模型的结构</li>
</ol>
<h3 id="Keras-to-ResNet"><a href="#Keras-to-ResNet" class="headerlink" title="Keras to ResNet"></a>Keras to ResNet</h3><p>首先导入一些需要用到的库</p>
<p>Keras是一个模型级的库，提供了快速构建深度学习网络的模块。Keras并不处理如张量乘法、卷积等底层操作。这些操作依赖于某种特定的、优化良好的张量操作库。Keras依赖于处理张量的库就称为“后端引擎”。Keras提供了三种后端引擎Theano&#x2F;Tensorflow&#x2F;CNTK，并将其函数统一封装，使得用户可以以同一个接口调用不同后端引擎的函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, load_model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> layer_utils</span><br><span class="line"><span class="keyword">from</span> keras.utils.data_utils <span class="keyword">import</span> get_file</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> SVG</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> model_to_dot</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> resnets_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> imshow</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line">K.set_image_data_format(<span class="string">&#x27;channels_last&#x27;</span>)</span><br><span class="line">K.set_learning_phase(<span class="number">1</span>)   <span class="comment"># 设置为训练/测试模式 ，分别是0/1</span></span><br></pre></td></tr></table></figure>

<h4 id="建立一个identity-block"><a href="#建立一个identity-block" class="headerlink" title="建立一个identity block"></a>建立一个identity block</h4><p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/87089704.jpg"></p>
<p>identity block是x[l]和 x[l+2]的size一样，就可以直接相加</p>
<p>用filters的list来存储三层的filter的个数，记录下一开始的X作为X_shortcut</p>
<p>然后开始主路的设计：先一个conv layer，然后一个BatchNormalization，axis&#x3D;3，是除了3以外的所有维度都normalization，也可以写成axis&#x3D;-1，然后是一个Activation(‘relu’)层</p>
<p>接下来的两层基本与第一层相同，只是filter的个数分别是F2,F3，filter的size中间那层是(f,f)</p>
<p>第三层结束之后得到的X加上一开始的X_shortcut，就是最终进入activation的值，这里的加法必须要用<code>keras.layers.Add()()([x1,x2])</code>或<code>keras.layers.add([x1, x2])</code>进行，直接用加号会出错</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: identity_block</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">identity_block</span>(<span class="params">X, f, filters, stage, block</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implementation of the identity block as defined in Figure 3</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)</span></span><br><span class="line"><span class="string">    f -- integer, specifying the shape of the middle CONV&#x27;s window for the main path</span></span><br><span class="line"><span class="string">    filters -- python list of integers, defining the number of filters in the CONV layers of the main path</span></span><br><span class="line"><span class="string">    stage -- integer, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    block -- string/character, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">&#x27;res&#x27;</span> + <span class="built_in">str</span>(stage) + block + <span class="string">&#x27;_branch&#x27;</span></span><br><span class="line">    bn_name_base = <span class="string">&#x27;bn&#x27;</span> + <span class="built_in">str</span>(stage) + block + <span class="string">&#x27;_branch&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save the input value. You&#x27;ll need this later to add back to the main path. </span></span><br><span class="line">    X_shortcut = X</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># First component of main path</span></span><br><span class="line">    X = Conv2D(filters = F1, kernel_size = (<span class="number">1</span>, <span class="number">1</span>), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">&#x27;valid&#x27;</span>, name = conv_name_base + <span class="string">&#x27;2a&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">&#x27;2a&#x27;</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">&#x27;same&#x27;</span>, name = conv_name_base + <span class="string">&#x27;2b&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">&#x27;2b&#x27;</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(filters = F3, kernel_size = (<span class="number">1</span>, <span class="number">1</span>), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">&#x27;valid&#x27;</span>, name = conv_name_base + <span class="string">&#x27;2c&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">&#x27;2c&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])  <span class="comment"># added = keras.layers.Add()([x1, x2])  ## equivalent to added = keras.layers.add([x1, x2])</span></span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>

<p>然后开始tensorflow测试一下identity block，定义一个A_prev的placeholder，类型是float，<code>shape=[3,4,4,6]</code>，X设为一个<code>[3,4,4,6]</code>的随机矩阵，用A_prev建立一个identity block，三层filter的个数是2,4,6，第二层的filter的形状是2*2，然后用sess run 变量初始化，接着run一下这个identity block，feed_dict数据是<code>A_prev:x</code>,<code>K.learning_phase(): 0</code>用于转换为训练模式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> test:</span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    A_prev = tf.placeholder(<span class="string">&quot;float&quot;</span>, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">    X = np.random.randn(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>)</span><br><span class="line">    A = identity_block(A_prev, f = <span class="number">2</span>, filters = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>], stage = <span class="number">1</span>, block = <span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">    test.run(tf.global_variables_initializer())</span><br><span class="line">    out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): <span class="number">0</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;out = &quot;</span> + <span class="built_in">str</span>(out[<span class="number">0</span>][<span class="number">1</span>][<span class="number">1</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<h4 id="建立一个convlutional-block"><a href="#建立一个convlutional-block" class="headerlink" title="建立一个convlutional block"></a>建立一个convlutional block</h4><p>convlutional block就是shortcut不是直接加到a[l+2]上面的，而是经过了一个conv layer和batch norm之后加的</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/5062663.jpg"></p>
<p>与建立identity layer的方法类似，记录X为X_shortcut，这里的shortcut到后面是要经过运算的，不是直接加的</p>
<p>每个conv layer 有一个kernel的initializer，<code> kernel_initializer = glorot_uniform(seed=0)</code>就是常用的Xavier 初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: convolutional_block</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convolutional_block</span>(<span class="params">X, f, filters, stage, block, s = <span class="number">2</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implementation of the convolutional block as defined in Figure 4</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)</span></span><br><span class="line"><span class="string">    f -- integer, specifying the shape of the middle CONV&#x27;s window for the main path</span></span><br><span class="line"><span class="string">    filters -- python list of integers, defining the number of filters in the CONV layers of the main path</span></span><br><span class="line"><span class="string">    stage -- integer, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    block -- string/character, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    s -- Integer, specifying the stride to be used</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">&#x27;res&#x27;</span> + <span class="built_in">str</span>(stage) + block + <span class="string">&#x27;_branch&#x27;</span></span><br><span class="line">    bn_name_base = <span class="string">&#x27;bn&#x27;</span> + <span class="built_in">str</span>(stage) + block + <span class="string">&#x27;_branch&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save the input value</span></span><br><span class="line">    X_shortcut = X</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">##### MAIN PATH #####</span></span><br><span class="line">    <span class="comment"># First component of main path </span></span><br><span class="line">    X = Conv2D(F1, (<span class="number">1</span>, <span class="number">1</span>), strides = (s,s),padding=<span class="string">&#x27;valid&#x27;</span>, name = conv_name_base + <span class="string">&#x27;2a&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">&#x27;2a&#x27;</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(F2, (f, f), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">&#x27;same&#x27;</span>, name = conv_name_base + <span class="string">&#x27;2b&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">&#x27;2b&#x27;</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(F3, (<span class="number">1</span>, <span class="number">1</span>), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">&#x27;valid&#x27;</span>, name = conv_name_base + <span class="string">&#x27;2c&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">&#x27;2c&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">##### SHORTCUT PATH #### (≈2 lines)</span></span><br><span class="line">    X_shortcut = Conv2D(F3, (<span class="number">1</span>, <span class="number">1</span>), strides = (s,s), padding = <span class="string">&#x27;valid&#x27;</span>, name = conv_name_base + <span class="string">&#x27;1&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X_shortcut)</span><br><span class="line">    X_shortcut = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">&#x27;1&#x27;</span>)(X_shortcut)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])</span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>

<p>同样来测试一下我们建立的convolutional block</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> test:</span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    A_prev = tf.placeholder(<span class="string">&quot;float&quot;</span>, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">    X = np.random.randn(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>)</span><br><span class="line">    A = convolutional_block(A_prev, f = <span class="number">2</span>, filters = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>], stage = <span class="number">1</span>, block = <span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">    test.run(tf.global_variables_initializer())</span><br><span class="line">    out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): <span class="number">0</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;out = &quot;</span> + <span class="built_in">str</span>(out[<span class="number">0</span>][<span class="number">1</span>][<span class="number">1</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<h4 id="建立一个50层的ResNet"><a href="#建立一个50层的ResNet" class="headerlink" title="建立一个50层的ResNet"></a>建立一个50层的ResNet</h4><p>结构如下图所示，分为5个stage，其中的conv block就是我们在上面建立的convolutional block，其中的ID block就是我们上面建立的identity block</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/92727700.jpg"></p>
<p>我们先给一个大小就可以定义一个输入的tensor，用Input方法实现</p>
<p>先进入一个zero padding，然后一个conv layer，batch norm，relu，max pool，接下来就是一大堆的block，然后接一个AvgPool，flatten一下，接一个FC layer，就得到了输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: ResNet50</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ResNet50</span>(<span class="params">input_shape = (<span class="params"><span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span></span>), classes = <span class="number">6</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implementation of the popular ResNet50 the following architecture:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; BATCHNORM -&gt; RELU -&gt; MAXPOOL -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; CONVBLOCK -&gt; IDBLOCK*3</span></span><br><span class="line"><span class="string">    -&gt; CONVBLOCK -&gt; IDBLOCK*5 -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; AVGPOOL -&gt; TOPLAYER</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    input_shape -- shape of the images of the dataset</span></span><br><span class="line"><span class="string">    classes -- integer, number of classes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    model -- a Model() instance in Keras</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the input as a tensor with shape input_shape</span></span><br><span class="line">    X_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Zero-Padding</span></span><br><span class="line">    X = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(X_input)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Stage 1</span></span><br><span class="line">    X = Conv2D(<span class="number">64</span>, (<span class="number">7</span>, <span class="number">7</span>), strides = (<span class="number">2</span>, <span class="number">2</span>), name = <span class="string">&#x27;conv1&#x27;</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = <span class="string">&#x27;bn_conv1&#x27;</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">&#x27;relu&#x27;</span>)(X)</span><br><span class="line">    X = MaxPooling2D((<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 2</span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage = <span class="number">2</span>, block=<span class="string">&#x27;a&#x27;</span>, s = <span class="number">1</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 3 (≈4 lines)</span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage = <span class="number">3</span>, block=<span class="string">&#x27;a&#x27;</span>, s = <span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">&#x27;d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 4 (≈6 lines)</span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage = <span class="number">4</span>, block=<span class="string">&#x27;a&#x27;</span>, s = <span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">&#x27;e&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">&#x27;f&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 5 (≈3 lines)</span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage = <span class="number">5</span>, block=<span class="string">&#x27;a&#x27;</span>, s = <span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># AVGPOOL (≈1 line). Use &quot;X = AveragePooling2D(...)(X)&quot;</span></span><br><span class="line">    X = AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>))(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># output layer</span></span><br><span class="line">    X = Flatten()(X)</span><br><span class="line">    X = Dense(classes, activation=<span class="string">&#x27;softmax&#x27;</span>, name=<span class="string">&#x27;fc&#x27;</span> + <span class="built_in">str</span>(classes), kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create model</span></span><br><span class="line">    model = Model(inputs = X_input, outputs = X, name=<span class="string">&#x27;ResNet50&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>接下来定义我们的model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = ResNet50(input_shape = (<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>), classes = <span class="number">6</span>)</span><br></pre></td></tr></table></figure>

<p>然后compile model，指定optimizer和loss以及metric</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>导入数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize image vectors</span></span><br><span class="line">X_train = X_train_orig/<span class="number">255.</span></span><br><span class="line">X_test = X_test_orig/<span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert training and test labels to one hot matrices</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># number of training examples = 1080</span></span><br><span class="line"><span class="comment"># number of test examples = 120</span></span><br><span class="line"><span class="comment"># X_train shape: (1080, 64, 64, 3)</span></span><br><span class="line"><span class="comment"># Y_train shape: (1080, 6)</span></span><br><span class="line"><span class="comment"># X_test shape: (120, 64, 64, 3)</span></span><br><span class="line"><span class="comment"># Y_test shape: (120, 6)</span></span><br></pre></td></tr></table></figure>

<p>1080张64*64的三通道图片，测试时120张64*64的三通道图片</p>
<p>接下来fit model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train, Y_train, epochs = <span class="number">20</span>, batch_size = <span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<p>最后evaluate模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">preds = model.evaluate(X_test, Y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Loss = &quot;</span> + <span class="built_in">str</span>(preds[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Test Accuracy = &quot;</span> + <span class="built_in">str</span>(preds[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>

<p>同样<code>summary()</code>和<code>plot_model</code>看看参数以及网络结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br><span class="line">plot_model(model, to_file=<span class="string">&#x27;model.png&#x27;</span>)</span><br><span class="line">SVG(model_to_dot(model).create(prog=<span class="string">&#x27;dot&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;svg&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-13/71188004.jpg"></p>
<h2 id="Week-Three-检测算法"><a href="#Week-Three-检测算法" class="headerlink" title="Week Three 检测算法"></a>Week Three 检测算法</h2><h3 id="目标定位"><a href="#目标定位" class="headerlink" title="目标定位"></a>目标定位</h3><p>目标检测主要有两类任务，一类是image classification 和 classification with localization，往往只有一个目标需要标记，另一类是detection，往往有多个目标需要标记</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/27032753.jpg"></p>
<p>当你需要标记目标位置的时候，你的神经网络的输出不仅是一个softmax的概率值，还有图像中心点的x，y坐标以及红框的宽和高的值，假设我们现在检测三类目标，分别是行人，汽车，摩托车，以及三类都没有的纯背景的情况，那么你的y应该设置为<br>$$<br>y&#x3D;\begin{bmatrix}P_c \b_x \b_y \b_h \b_w \c_1 \c_2 \c_3 \end{bmatrix}<br>$$</p>
<p>其中$P_c$表示的是图中有无目标，如果有目标那么就要定位$b_x,b_y,b_h,b_w$，以及他们的分类$c_1,c_2,c_3$</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/76557389.jpg"></p>
<p>当$P_c &#x3D; 1$的时候，y的所有参数都是需要关心的</p>
<p>当$P_c &#x3D; 0$，除了$P_c $以外的其余参数都不用关心，图中用问号表示</p>
<p>损失函数可以表示为<br>$$<br>L(\hat y,y)&#x3D;\left{\begin{matrix}<br>(\hat y_1,y_1)^2+\ldots+(\hat y_8,y_8)^2 &amp; if &amp; y&#x3D;1\<br>(\hat y_1,y_1)^2 &amp; if &amp; y&#x3D;0<br>\end{matrix}\right.<br>$$</p>
<h3 id="特征点检测"><a href="#特征点检测" class="headerlink" title="特征点检测"></a>特征点检测</h3><p>当你检测一个人或者是一个姿势的时候，你可能需要的不是像检测汽车那样只要一个中心点，你可能需要很多个点来检测人脸的五官，或者不同的点来检测一个人的姿势，此时你的y就有很多个点</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/36562583.jpg"></p>
<h3 id="利用滑动窗口进行目标检测"><a href="#利用滑动窗口进行目标检测" class="headerlink" title="利用滑动窗口进行目标检测"></a>利用滑动窗口进行目标检测</h3><p>用一个正方形框在图像上以一定步长滑动，每次检测框内的图像，这就是滑动窗口的含义，用不同大小的框可以多次进行</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/76981350.jpg"></p>
<p>但是滑动窗口的计算成本非常大，如果你的步长选的比较小（精度比较高），那么你要输入系统的图片非常多，计算量就非常大</p>
<h3 id="使用卷积实现滑动窗口"><a href="#使用卷积实现滑动窗口" class="headerlink" title="使用卷积实现滑动窗口"></a>使用卷积实现滑动窗口</h3><p>使用卷积实现滑动窗口，首先要看看如何把FC层转换为卷积层，在本来应该flatten的地方，再用一组f大小与原图相等的filter，将它变成1*1的volume，然后反复使用1*1的filter，直到最后大小等于1*1*4</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/70781915.jpg"></p>
<p>同样，在滑动窗口的过程中，有很多的卷积步骤是重复的，因此我们可以使用卷积来避免每个滑动窗口都经历整个卷积神经网络</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/4716774.jpg"></p>
<h3 id="获得更加精确的边界框"><a href="#获得更加精确的边界框" class="headerlink" title="获得更加精确的边界框"></a>获得更加精确的边界框</h3><p>YOLO(You Only Look Once)算法是一个很好用的目标检测算法，先讲图片分割成很多个小的矩形，每个矩形中间如果有某个目标对象的中心点，那么这个方框的Y的第一个值$P_c$就为1，否则为0，最后得到一个3*3*8的volume，这个volume就是预测的结果，因为这个算法使用了卷积的方法，因此速度很快</p>
<p>我们来看个例子，比如下图，原图是100*100的大小，我们划分成3*3的格子，绿色和橙色格子有目标，找出中心点，然后标记出方框，绿色块的y值如右边的绿色y所示，橙色如橙色标识的y所示，其余的都是紫色标记</p>
<p>通常我们划分的块会更多一些，以便更加精确地定位图像</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/65964893.jpg"></p>
<p>边框的标记方法是给出中心点的坐标x，y，已经图像的高度h和宽度w，因为我们对每个小方块的坐标定义为左上角是(0,0)，右下角是(1,1)，所以x,y一定是在0到1之间的值，但是目标的大小可能超出一个方块，所以h和w可以是大于0的任何值（当然也可以大于1），如下图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/31698060.jpg"></p>
<h3 id="交并比（intersection-over-union）"><a href="#交并比（intersection-over-union）" class="headerlink" title="交并比（intersection over union）"></a>交并比（intersection over union）</h3><p>交并比：一个方框与真实结果的交集与其并集的比，用于评价目标检测算法的精度</p>
<p>最好情况的交并比是1，一般来说，如果你的交并比（IoU）&gt;&#x3D;0.5，就认为你的检测是正确的</p>
<h3 id="非最大值抑制-Non-max-Suppression"><a href="#非最大值抑制-Non-max-Suppression" class="headerlink" title="非最大值抑制(Non-max Suppression)"></a>非最大值抑制(Non-max Suppression)</h3><p>加入你在下图中检测汽车，你把图片分成了19*19大小的网格，两辆车的中心分别是绿色点和黄色点，理论上来说它们各自的中心点应该只会被标记一次，但是你在运行网络的时候，每一个网格都是独立运行的，所以旁边的网格可能也会认为自己就在图片中心，同一个目标可能会被标记好多次，因此引入非最大值抑制的策略来保证每个目标只被标记一次</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/39766648.jpg"></p>
<p>假设我们现在已经得到了很多个框，你需要去找到哪个框是真的有效的，如下图</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/21084208.jpg"></p>
<p>具体做法如下：</p>
<ol>
<li>首先，你将那些概率值都低于0.6的框给删除</li>
<li>只要这里还剩任何框：选择现在概率最大的框最为结果，删除任何与这个结果IoU大于等于0.5的盒子</li>
<li>只要还有框没有标记就跳到第二步</li>
</ol>
<h3 id="Anchor-Box"><a href="#Anchor-Box" class="headerlink" title="Anchor Box"></a>Anchor Box</h3><p>Anchor Box是用来当你需要检测多个目标的时候，你先给几个预先给定的anchor box，将结果的y联合起来</p>
<p>比如你现在检测行人和车辆，行人的车辆应该是高长的，车辆的扁宽的，本来y是8维的，然后现在连接起来就有16维</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/12260966.jpg"></p>
<p>然后我们将两个anchor box 和 我们之前圈出来的框计算IoU，图像将被分到高IoU的部分</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/7317445.jpg"></p>
<h3 id="YOLO算法的完整描述"><a href="#YOLO算法的完整描述" class="headerlink" title="YOLO算法的完整描述"></a>YOLO算法的完整描述</h3><p>如果你在进行一个定位行人，汽车，摩托车的YOLO算法，如下图，先将图片分成3*3的网格，对每一个网格进行检测，现在设定了2个anchor box，那么最终的输出是3*3*16的结果</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/15432401.jpg"></p>
<p>我们来看看如何做预测，如下图，我们将最终的结果全为$P_c$全为0的分类成背景，为1的部分去找对应的c的分类</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/38705005.jpg"></p>
<p>我们再来看看如何使用non-max suppress，先从图中移除那些概率很低的框，然后分别对三个类别（行人，汽车，摩托车）进行non-max suppress得到最终的预测</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-14/49481234.jpg"></p>
<h2 id="Week-four"><a href="#Week-four" class="headerlink" title="Week four"></a>Week four</h2><h3 id="人脸识别的术语"><a href="#人脸识别的术语" class="headerlink" title="人脸识别的术语"></a>人脸识别的术语</h3><p>人脸识别任务大致分为两类，分别是face verification 和 face recognition：</p>
<ul>
<li>face verification：指的是给一张图片，判定是否是你要找的那个人，是一个二分类的问题</li>
<li>face recognition：是给一张图片，判定他是谁，是一个多分类问题</li>
</ul>
<h3 id="单样本学习问题-one-shot-learning"><a href="#单样本学习问题-one-shot-learning" class="headerlink" title="单样本学习问题(one shot learning)"></a>单样本学习问题(one shot learning)</h3><p>通常识别任务要求在只有一张图片的情况下进行识别，但是从传统来说，只有一个训练样本的效果是很差的</p>
<p>解决的办法就是，学习出一个相似性函数，给定两张图片，如果两张图片的相似度比较大（距离比较小），那么两张图片就是同一个人。我们设定一个阈值，如果小于这个阈值，我们认为是同一个人，如果大于这个阈值，我们认为是不同的人。这样，即使有新的人加入这个系统，你的系统依然可以进行判断</p>
<h3 id="孪生网络（Siamese-Network）"><a href="#孪生网络（Siamese-Network）" class="headerlink" title="孪生网络（Siamese Network）"></a>孪生网络（Siamese Network）</h3><p>普通的卷积神经网络是先经过几个卷基层，然后经过一个FC layer，最后一个softmax进行判别，我们在这里删除最后的softmax层，将最后的FC层的输出作为一张图片的编码</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/10704951.jpg"></p>
<p>将这些输出的编码作为结果，计算距离，并使得同一个人的不同图片距离小，不同人的图片距离大，以此作为目标进行反向传播，具体的loss函数被称为triple loss function</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/66344361.jpg"></p>
<h3 id="三重损失函数（triple-loss-function）"><a href="#三重损失函数（triple-loss-function）" class="headerlink" title="三重损失函数（triple loss function）"></a>三重损失函数（triple loss function）</h3><p>我们每次进行训练的图片应该有三张：Anchor，Positive，Negative，分别代表原始图片，同一个人的图片，另一个人的图片，计算Anchor和Positive以及Negative之间的距离，记作d(A,P)和d(A,N)，计算方法是通过神经网络给出的编码，计算欧式距离，要求同一个人的不同图片距离小(d(A,P)小)，不同人的图片距离大（d(A,N)大），并且他们之间不能是基本相同的大小，因为那样对于分类器来说是比较难区分的，我们把差距超过一定范围$\alpha$的才能称为不同人，如下图所示</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/35397965.jpg"></p>
<p>那么损失函数可以是上图中的右式移到左边，那么要求这个损失小于等于0，那么我们取Loss为<br>$$<br>L(A,P.N)&#x3D;max(||f(A)-f(N)||^2-||f(A)-f(N)||^2+\alpha,:0)<br>$$<br>那么代价函数就是<br>$$<br>J&#x3D;\sum_{i&#x3D;1}^mL(A^{(i)},P^{(i)},N^{(i)})<br>$$<br>训练的数据要足够的大，一个人应该有好几张图片，如果只有一张图片是很难训练的</p>
<p>如何选择APN也是有要求的，如果你A,P,N都随机选择，那么两张不同人的图片距离一般来说是肯定大于一个人的两张图片的，所以我们应该选那些尽可能接近的距离值去训练，也就是d(A,P)和d(A,N)要尽量靠近一些</p>
<p>在深度学习中，这些系统的名字一般选择为<code>xxNet</code>或者是<code>Deepxx</code>，比如这里的FaceNet和之前提到的DeepFace</p>
<h3 id="二分类的人脸识别"><a href="#二分类的人脸识别" class="headerlink" title="二分类的人脸识别"></a>二分类的人脸识别</h3><p>另一种进行人脸识别的方法是二分类，当你有一个新的图片需要分类的时候，将它输入一个已经训练好的卷积神经网络，得到一个编码，与系统中另一张图片的编码经过一个logistic单元，最终的$\hat y$如果为1，证明图片来自同一个人，否则来自于不同人</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/58169041.jpg"></p>
<p>这里有个节省计算能力的好办法，就是系统中的图片，你应该全部先通过卷及网络算出编码，直接存储编码，这样每次你只需要将新图片经过这个神经网络得到编码，再做一个logistic计算就可以了</p>
<h3 id="风格迁移"><a href="#风格迁移" class="headerlink" title="风格迁移"></a>风格迁移</h3><h4 id="什么是风格迁移"><a href="#什么是风格迁移" class="headerlink" title="什么是风格迁移"></a>什么是风格迁移</h4><p>如下图，我们将原图(Content)称为C，风格图（Style）称为S，生成的图片（Gnerated image）称为G</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/56114233.jpg"></p>
<h3 id="深度卷积神经网络究竟学的是什么"><a href="#深度卷积神经网络究竟学的是什么" class="headerlink" title="深度卷积神经网络究竟学的是什么"></a>深度卷积神经网络究竟学的是什么</h3><p>卷积神经网络的前面层，是一些图片的边缘信息，越到后面的层，信息越丰富</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-15/52977504.jpg"></p>
<h3 id="风格迁移的代价函数"><a href="#风格迁移的代价函数" class="headerlink" title="风格迁移的代价函数"></a>风格迁移的代价函数</h3><p>我们用C表示Content这张图，用S表示Style这张图，G代表Generated image，要求定义的代价函数在最小化时使用梯度下降：<br>$$<br>J(G) &#x3D; \alpha J_{content}(C,G) + \beta J_{style}(S,G)<br>$$<br>风格迁移的过程：</p>
<ol>
<li>随机初始化G</li>
<li>进行梯度下降，是的cost function变小，然后输出的图像和C和S的混合越来越像</li>
</ol>
<h4 id="Content-cost-function"><a href="#Content-cost-function" class="headerlink" title="Content cost function"></a>Content cost function</h4><p>你用第$l$层的卷积网络去计算你的content cost function，这个层数不能太靠前（前面全是边缘信息），也不能太靠后（太靠后已经是完整的图片了），你的Content cost function只需要计算第$l$层的Content和Generated 的输出的相似度，我们在这里使用L-2范数<br>$$<br>J_{content}(C,G)&#x3D;||a^{<a href="C">l</a>}-a^{<a href="G">l</a>}||^2<br>$$</p>
<h4 id="Style-cost-function"><a href="#Style-cost-function" class="headerlink" title="Style cost function"></a>Style cost function</h4><p>要定义S和G的风格相似度，我们要来看看如何定义风格的相似，这里引入一个Style matrix的概念，用于定义不同层之间的像素值的乘积和，用$a_{i,j,k}^{[l]}$表示第$l$层的一个像素点，用$G^{[l]}$表示第l层的Style Matrix<br>$$<br>G^{<a href="S">l</a>}<em>{kk\prime} &#x3D; \sum</em>{i&#x3D;1}^{n_H^{[l]}}\sum_{j&#x3D;1}^{n_W^{[l]}}a_{ijk}^{<a href="S">l</a>}a_{ijk\prime}^{<a href="S">l</a>} \<br>G^{<a href="G">l</a>}<em>{kk\prime} &#x3D; \sum</em>{i&#x3D;1}^{n_H^{[l]}}\sum_{j&#x3D;1}^{n_W^{[l]}}a_{ijk}^{<a href="G">l</a>}a_{ijk\prime}^{<a href="G">l</a>} \<br>$$<br>第l层的style cost function就用这两个style function的相似度来计算<br>$$<br>\begin{array}{rcl}<br>J_{style}^{[l]}(S,G)  &amp;&#x3D;&amp; \frac{1}{(…)}||G^{<a href="S">l</a>}-G^{<a href="G">l</a>}||^2 \<br>&amp;&#x3D;&amp; \frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2}\sum_k\sum_{k{\prime}}(G^{<a href="S">l</a>}<em>{kk\prime}-G^{<a href="G">l</a>}</em>{kk\prime})<br>\end{array}<br>$$<br>通常一层的效果不够好，因此我们多用几层<br>$$<br>J_{style}(S,G)&#x3D;\sum_l\lambda^{[l]}J_{style}^{[l]}(S,G)<br>$$<br>最终的J就是把content和style的J加起来<br>$$<br>J(G) &#x3D; \alpha J_{content}(C,G) + \beta J_{style}(S,G)<br>$$</p>
<h3 id="1D和3D数据的卷积"><a href="#1D和3D数据的卷积" class="headerlink" title="1D和3D数据的卷积"></a>1D和3D数据的卷积</h3><p>1D数据通常是信号数据，你用的卷积核应该也是1D的，比如你一开始是14*1的信号，卷积16个5*1的filter，变成</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-16/99066781.jpg"></p>
<p>3D图像通常有CT图，视频之类的，有长，宽，深度三个维度，</p>
<p><img src="https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/pics/18-5-16/8799779.jpg"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/deeplearning/" rel="tag"># deeplearning</a>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/07/Coursera-deeplearning-ai-%EF%BC%88%E4%B8%89%EF%BC%89/" rel="next" title="Coursera-deeplearning-ai-（三）">
                <i class="fa fa-chevron-left"></i> Coursera-deeplearning-ai-（三）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/16/Coursera-deeplearning-ai-%EF%BC%88%E4%BA%94%EF%BC%89/" rel="prev" title="Coursera-deeplearning-ai-（五）">
                Coursera-deeplearning-ai-（五） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">95</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">45</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">61</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-One"><span class="nav-number">1.</span> <span class="nav-text">Week One</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="nav-number">1.1.</span> <span class="nav-text">计算机视觉</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8%E5%8D%B7%E7%A7%AF%E8%BF%9B%E8%A1%8C%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.2.</span> <span class="nav-text">利用卷积进行边缘检测的示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E5%A4%9A%E7%9A%84%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B"><span class="nav-number">1.3.</span> <span class="nav-text">更多的边缘检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#padding-%E6%89%A9%E5%85%85"><span class="nav-number">1.4.</span> <span class="nav-text">padding 扩充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%A6%E6%AD%A5%E9%95%BF%E7%9A%84%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.5.</span> <span class="nav-text">带步长的卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AFRGB%E5%9B%BE%E5%83%8F"><span class="nav-number">1.6.</span> <span class="nav-text">卷积RGB图像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.7.</span> <span class="nav-text">单层卷积神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="nav-number">1.8.</span> <span class="nav-text">简单的卷积网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pooling-Layers"><span class="nav-number">1.9.</span> <span class="nav-text">Pooling Layers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.10.</span> <span class="nav-text">一个完整的卷积神经网络示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.11.</span> <span class="nav-text">为什么要用卷积神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8TensorFlow%E6%90%AD%E5%BB%BA%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.12.</span> <span class="nav-text">利用TensorFlow搭建卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#read-data"><span class="nav-number">1.12.1.</span> <span class="nav-text">read data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#one-hot-transfer"><span class="nav-number">1.12.2.</span> <span class="nav-text">one_hot transfer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Create-Placeholder"><span class="nav-number">1.12.3.</span> <span class="nav-text">Create Placeholder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#initialize-parameters"><span class="nav-number">1.12.4.</span> <span class="nav-text">initialize_parameters</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Forward-propagation"><span class="nav-number">1.12.5.</span> <span class="nav-text">Forward propagation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E4%BB%A3%E4%BB%B7"><span class="nav-number">1.12.6.</span> <span class="nav-text">计算代价</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8Bmodel"><span class="nav-number">1.12.7.</span> <span class="nav-text">建立model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-Two"><span class="nav-number">2.</span> <span class="nav-text">Week Two</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C"><span class="nav-number">2.1.</span> <span class="nav-text">经典网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LeNet-5"><span class="nav-number">2.1.1.</span> <span class="nav-text">LeNet-5</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AlexNet"><span class="nav-number">2.1.2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#VGG-16"><span class="nav-number">2.1.3.</span> <span class="nav-text">VGG-16</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C-ResNet"><span class="nav-number">2.2.</span> <span class="nav-text">残差网络(ResNet)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E5%8F%AF%E4%BB%A5%E8%A1%A8%E7%8E%B0%E5%BE%97%E6%9B%B4%E5%A5%BD"><span class="nav-number">2.3.</span> <span class="nav-text">为什么残差网络可以表现得更好</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-times-1-%E7%9A%84%E5%8D%B7%E7%A7%AF%EF%BC%88network-in-network%EF%BC%89"><span class="nav-number">2.4.</span> <span class="nav-text">$1\times 1$的卷积（network in network）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Inception-Network"><span class="nav-number">2.5.</span> <span class="nav-text">Inception Network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%BC%80%E6%BA%90%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.6.</span> <span class="nav-text">使用开源的深度学习实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.7.</span> <span class="nav-text">迁移学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8D%87"><span class="nav-number">2.8.</span> <span class="nav-text">数据提升</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%BB%E5%8A%A1%E7%9A%84%E7%BB%8F%E9%AA%8C"><span class="nav-number">2.9.</span> <span class="nav-text">计算机视觉任务的经验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Keras-tutorial"><span class="nav-number">2.10.</span> <span class="nav-text">Keras tutorial</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Keras-to-ResNet"><span class="nav-number">2.11.</span> <span class="nav-text">Keras to ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AAidentity-block"><span class="nav-number">2.11.1.</span> <span class="nav-text">建立一个identity block</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AAconvlutional-block"><span class="nav-number">2.11.2.</span> <span class="nav-text">建立一个convlutional block</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AA50%E5%B1%82%E7%9A%84ResNet"><span class="nav-number">2.11.3.</span> <span class="nav-text">建立一个50层的ResNet</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-Three-%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">Week Three 检测算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D"><span class="nav-number">3.1.</span> <span class="nav-text">目标定位</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B"><span class="nav-number">3.2.</span> <span class="nav-text">特征点检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E8%BF%9B%E8%A1%8C%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-number">3.3.</span> <span class="nav-text">利用滑动窗口进行目标检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B0%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="nav-number">3.4.</span> <span class="nav-text">使用卷积实现滑动窗口</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%BE%97%E6%9B%B4%E5%8A%A0%E7%B2%BE%E7%A1%AE%E7%9A%84%E8%BE%B9%E7%95%8C%E6%A1%86"><span class="nav-number">3.5.</span> <span class="nav-text">获得更加精确的边界框</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E5%B9%B6%E6%AF%94%EF%BC%88intersection-over-union%EF%BC%89"><span class="nav-number">3.6.</span> <span class="nav-text">交并比（intersection over union）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9D%9E%E6%9C%80%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6-Non-max-Suppression"><span class="nav-number">3.7.</span> <span class="nav-text">非最大值抑制(Non-max Suppression)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Anchor-Box"><span class="nav-number">3.8.</span> <span class="nav-text">Anchor Box</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YOLO%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%8C%E6%95%B4%E6%8F%8F%E8%BF%B0"><span class="nav-number">3.9.</span> <span class="nav-text">YOLO算法的完整描述</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-four"><span class="nav-number">4.</span> <span class="nav-text">Week four</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%9A%84%E6%9C%AF%E8%AF%AD"><span class="nav-number">4.1.</span> <span class="nav-text">人脸识别的术语</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98-one-shot-learning"><span class="nav-number">4.2.</span> <span class="nav-text">单样本学习问题(one shot learning)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%AA%E7%94%9F%E7%BD%91%E7%BB%9C%EF%BC%88Siamese-Network%EF%BC%89"><span class="nav-number">4.3.</span> <span class="nav-text">孪生网络（Siamese Network）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E9%87%8D%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%88triple-loss-function%EF%BC%89"><span class="nav-number">4.4.</span> <span class="nav-text">三重损失函数（triple loss function）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB"><span class="nav-number">4.5.</span> <span class="nav-text">二分类的人脸识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="nav-number">4.6.</span> <span class="nav-text">风格迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="nav-number">4.6.1.</span> <span class="nav-text">什么是风格迁移</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A9%B6%E7%AB%9F%E5%AD%A6%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">4.7.</span> <span class="nav-text">深度卷积神经网络究竟学的是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%E7%9A%84%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0"><span class="nav-number">4.8.</span> <span class="nav-text">风格迁移的代价函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Content-cost-function"><span class="nav-number">4.8.1.</span> <span class="nav-text">Content cost function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Style-cost-function"><span class="nav-number">4.8.2.</span> <span class="nav-text">Style cost function</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1D%E5%92%8C3D%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8D%B7%E7%A7%AF"><span class="nav-number">4.9.</span> <span class="nav-text">1D和3D数据的卷积</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jeffrey Pacino</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
